{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2063, 37) (2063, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# chargement des donnees + calcul baseline\n",
    "\n",
    "data_folder = Path('./')\n",
    "\n",
    "df = pd.read_csv(data_folder/'dataset.csv', dtype='int8')\n",
    "y = pd.read_csv(data_folder/'y.csv', dtype='int8')\n",
    "\n",
    "print(df.shape, y.shape)\n",
    "\n",
    "# baseline\n",
    "# print(y['0'].value_counts()[1])\n",
    "# 1 - (y['0'].value_counts()[1] / y['0'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in cv.split(df, y):\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    X_ = poly.fit_transform(df.iloc[train_index])\n",
    "    predict_ = poly.fit_transform(df.iloc[test_index])\n",
    "\n",
    "    clf = linear_model.LinearRegression()\n",
    "#     reg = clf.fit(df.iloc[train_index], y.iloc[train_index].values.ravel())\n",
    "    reg = clf.fit(X_, y.iloc[train_index].values.ravel())\n",
    "#     print(y.iloc[test_index].values.ravel())\n",
    "#     print(reg.predict(predict_))\n",
    "#     print(reg.predict(df.iloc[test_index]))\n",
    "#     print(reg.score(df.iloc[test_index], y.iloc[test_index].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'oob_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-60fca1496185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'oob_score_'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=42, n_estimators=100)\n",
    "\n",
    "for train_index, test_index in cv.split(df, y):\n",
    "    regr.fit(df.iloc[train_index], y.iloc[train_index].values.ravel())\n",
    "    print(regr.score(df.iloc[test_index], y.iloc[test_index].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# training du xgboost\n",
    "\n",
    "#param_range = [0.001,0.01,0.1,1,10,100]\n",
    "param_range = [1]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for i in param_range:\n",
    "    classifier = xgb.XGBClassifier(max_depth=5, n_estimators=400, learning_rate=0.04, silent=0, random_state=42)\n",
    "\n",
    "    acc = []\n",
    "    tprs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    for train_index, test_index in cv.split(df, y):\n",
    "        model = classifier.fit(df.iloc[train_index], y.iloc[train_index].values.ravel())\n",
    "        y_hat = model.predict(df.iloc[test_index])\n",
    "        # Making the Confusion Matrix\n",
    "        cm = confusion_matrix(y.iloc[test_index], (y_hat>0.5))\n",
    "        print('The Confusion Matrix is: ','\\n', cm)\n",
    "        # Calculate the accuracy on test set\n",
    "        predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
    "        print('The Accuracy on Test Set is: ', predict_accuracy_on_test_set)\n",
    "        \n",
    "#         aucs.append(roc_auc)\n",
    "\n",
    "#     mean_tpr = np.mean(tprs, axis=0)\n",
    "#     mean_tpr[-1] = 1.0\n",
    "#     mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    \n",
    "\n",
    "\n",
    "    print('param=%s Accuracy %0.3f' % (str(i), predict_accuracy_on_test_set))\n",
    "#     print(aucs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
